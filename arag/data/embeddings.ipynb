{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shargo/dietbot/arag/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Reading PDF: 100%|██████████| 100/100 [00:01<00:00, 77.84it/s]\n",
      "Generating Embeddings: 100%|██████████| 251/251 [00:23<00:00, 10.74it/s]\n",
      "Add of existing embedding ID: 0\n",
      "Add of existing embedding ID: 1\n",
      "Add of existing embedding ID: 2\n",
      "Add of existing embedding ID: 3\n",
      "Add of existing embedding ID: 4\n",
      "Add of existing embedding ID: 5\n",
      "Add of existing embedding ID: 6\n",
      "Add of existing embedding ID: 7\n",
      "Add of existing embedding ID: 8\n",
      "Add of existing embedding ID: 9\n",
      "Add of existing embedding ID: 10\n",
      "Add of existing embedding ID: 11\n",
      "Add of existing embedding ID: 12\n",
      "Add of existing embedding ID: 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. Embeddings stored in Chroma collection 'pdf_embeddings'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import tqdm\n",
    "import PyPDF2\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline as hf_pipeline\n",
    "\n",
    "def text_formatter(text: str) -> str:\n",
    "    cleaned_text = text.replace(\"\\n\", \" \").strip()\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)\n",
    "    return cleaned_text\n",
    "\n",
    "def split_into_sentences(text: str) -> list[str]:\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "    return [s.strip() for s in sentences if s.strip()]\n",
    "\n",
    "def open_and_read_pdf(pdf_path: str) -> list[dict]:\n",
    "    pages_and_texts = []\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        for page_number in tqdm.tqdm(range(len(pdf_reader.pages)), desc=\"Reading PDF\"):\n",
    "            text = pdf_reader.pages[page_number].extract_text()\n",
    "            text = text_formatter(text)\n",
    "            pages_and_texts.append({\n",
    "                \"page_number\": page_number,\n",
    "                \"text\": text\n",
    "            })\n",
    "    return pages_and_texts\n",
    "\n",
    "def split_list(input_list: list, slice_size: int, overlap: int = 5) -> list[list[str]]:\n",
    "    chunks = []\n",
    "    for i in range(0, len(input_list), slice_size - overlap):\n",
    "        chunk = input_list[i:i + slice_size]\n",
    "        if chunk:\n",
    "            chunks.append(chunk)\n",
    "    return chunks\n",
    "\n",
    "def chunk_pdf_text(pages_and_texts: list[dict], num_sentence_chunk_size: int = 10, overlap: int = 5) -> pd.DataFrame:\n",
    "    # Add sentence-level splits\n",
    "    for item in pages_and_texts:\n",
    "        item[\"sentences\"] = split_into_sentences(item[\"text\"])\n",
    "\n",
    "    # Chunk sentences into overlapping windows\n",
    "    pages_and_chunks = []\n",
    "    for item in pages_and_texts:\n",
    "        item[\"sentence_chunks\"] = split_list(\n",
    "            input_list=item[\"sentences\"],\n",
    "            slice_size=num_sentence_chunk_size,\n",
    "            overlap=overlap\n",
    "        )\n",
    "        for sentence_chunk in item[\"sentence_chunks\"]:\n",
    "            joined_sentence_chunk = \" \".join(sentence_chunk)\n",
    "            joined_sentence_chunk = re.sub(r'\\s+', ' ', joined_sentence_chunk)\n",
    "            chunk_dict = {\n",
    "                \"page_number\": item[\"page_number\"],\n",
    "                \"sentence_chunk\": joined_sentence_chunk,\n",
    "                \"chunk_char_count\": len(joined_sentence_chunk),\n",
    "                \"chunk_word_count\": len(joined_sentence_chunk.split(\" \")),\n",
    "                \"chunk_token_count\": len(joined_sentence_chunk) / 4.0  # rough token estimate\n",
    "            }\n",
    "            pages_and_chunks.append(chunk_dict)\n",
    "\n",
    "    # Convert to DataFrame and filter by minimum token length (optional)\n",
    "    df = pd.DataFrame(pages_and_chunks)\n",
    "    return df\n",
    "\n",
    "def embed_chunks(df: pd.DataFrame, embedding_model_name: str = \"all-mpnet-base-v2\", min_token_length: int = 30) -> list[dict]:\n",
    "    # Filter short chunks\n",
    "    filtered = df[df[\"chunk_token_count\"] > min_token_length].to_dict(orient=\"records\")\n",
    "\n",
    "    # Load embedding model\n",
    "    embedding_model = SentenceTransformer(embedding_model_name, device=\"cpu\")\n",
    "\n",
    "    # Generate embeddings\n",
    "    for item in tqdm.tqdm(filtered, desc=\"Generating Embeddings\"):\n",
    "        item[\"embedding\"] = embedding_model.encode(item[\"sentence_chunk\"])\n",
    "\n",
    "    return filtered\n",
    "\n",
    "def store_in_chroma(chunks: list[dict], collection_name: str, chroma_db_path: str = \"./chroma_db\", embedding_model_name: str = \"all-mpnet-base-v2\") -> None:\n",
    "    chroma_client = chromadb.PersistentClient(path=chroma_db_path)\n",
    "    embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "        model_name=embedding_model_name\n",
    "    )\n",
    "\n",
    "    collection = chroma_client.get_or_create_collection(\n",
    "        name=collection_name,\n",
    "        embedding_function=embedding_function,\n",
    "        metadata={\"hnsw:space\": \"cosine\"}  # Using cosine similarity\n",
    "    )\n",
    "\n",
    "    ids = [str(i) for i in range(len(chunks))]\n",
    "    documents = [item[\"sentence_chunk\"] for item in chunks]\n",
    "    metadatas = [{\"page_number\": str(item[\"page_number\"])} for item in chunks]\n",
    "    embeddings = [item[\"embedding\"].tolist() for item in chunks]\n",
    "\n",
    "    collection.upsert(\n",
    "        ids=ids,\n",
    "        documents=documents,\n",
    "        metadatas=metadatas,\n",
    "        embeddings=embeddings\n",
    "    )\n",
    "    print(f\"Embeddings stored in Chroma collection '{collection_name}' at {chroma_db_path}.\")\n",
    "\n",
    "def query_chroma(query: str, collection_name: str, chroma_db_path: str = \"./chroma_db\", embedding_model_name: str = \"all-mpnet-base-v2\", n_results: int = 3) -> dict:\n",
    "    embedding_model = SentenceTransformer(embedding_model_name, device=\"cpu\")\n",
    "    query_embedding = embedding_model.encode(query).tolist()\n",
    "\n",
    "    chroma_client = chromadb.PersistentClient(path=chroma_db_path)\n",
    "    collection = chroma_client.get_collection(name=collection_name)\n",
    "\n",
    "    # Query\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=n_results\n",
    "    )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_chroma(query: str, collection_name: str, chroma_db_path: str = \"./chroma_db\", embedding_model_name: str = \"all-mpnet-base-v2\", n_results: int = 3) -> dict:\n",
    "    # Load embedding model to embed the query\n",
    "    embedding_model = SentenceTransformer(embedding_model_name, device=\"cpu\")\n",
    "    query_embedding = embedding_model.encode(query).tolist()\n",
    "\n",
    "    # Connect to Chroma and retrieve the collection\n",
    "    chroma_client = chromadb.PersistentClient(path=chroma_db_path)\n",
    "    collection = chroma_client.get_collection(name=collection_name)\n",
    "\n",
    "    # Query\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=n_results\n",
    "    )\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = collection.query(\n",
    "    query_texts=[\"This is a query about diabetes\"],\n",
    "    n_results=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': [['53', '11']], 'embeddings': None, 'documents': [['Food and Nutrition Handbook for Extension Workers10WATER-SOLUBLE VITAMINS (CONTINUED) Vitamin B3 (Niacin)Fish, meat, chicken, eggs, whole grain cerealsEnables energy production in the body, supports appetite and central nervous system functions • Dermatitis • Dementia • Diarrhoea Vitamin B6 (pyridoxine)Legumes, avocado, dark green leafy vegetables (DGLV), whole grains, nuts and seeds, cabbage, banana, liver, chicken, meat, fish, potatoes, water melon, sun flowers seedsFacilitates metabolism and absorption of fats and proteins, promotes red blood cells formation, production of protein and nerve transmitters, antioxidantsTiredness, anaemia, irritability, depression, sore tongue, nausea, muscle twitching, dizziness, dermatitis (skin problem), neuropathy (nerve problem) Vitamin B 12 (cyanocobalamin)Seafood, liver, kidney, heart, whole grains, tuna, yoghurt, eggs, cheese, meat, chickenFormation of red blood cells, affects white blood cells, maintains nerve and gastrointestinal tissueTiredness, anaemia, confusion, numbness, nerve problems, ringing in ears, dementia, memory problems Folic acid Kidney, liver, nuts, legumes, eggs, green vegetables, whole grains, avocado, oranges, fishContributes to synthesis of new red blood cells and gastrointestinal cells, aids cell division and growthDiarrhoea, sore red tongue, anaemia, heartburn, fatigue, confusion, depression and dementia Vitamin C Guavas, sweet pepper, leafy green vegetables, oranges, lemons, tomatoes, most fruitsBuilds healthy bones, teeth and gums, helps fight infection, helps non-heme iron absorption, serves as an antioxidants, helps in protein metabolismBleeding gums, bruise easily, slow heal, anaemia, muscle and joint pain, frequent colds', '16 CHAPTER TWO: MALNUTRITION AND ITS PREVENTION .................................. 17 What is malnutrition? ............................................................................................. 17 Types of malnutrition .............................................................................................. 17 a) Undernutrition ............................................................................................ 17 b) Micronutrient malnutrition (lack of minerals and vitamins) ...................... 19 c) Overnutrition ............................................................................................... 19 Prevalence of malnutrition in Uganda .................................................................... 20 Causes of malnutrition? ..........................................................................................']], 'uris': None, 'data': None, 'metadatas': [[{'page_number': '21'}, {'page_number': '5'}]], 'distances': [[0.6276715993881226, 0.629321813583374]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "def load_optimized_llm(model_name: str = \"nvidia/Mistral-NeMo-Minitron-8B-Instruct\") -> tuple:\n",
    "    \"\"\"\n",
    "    Loads and optimizes the LLM model using torch.compile.\n",
    "\n",
    "    Args:\n",
    "        model_name: The model identifier from Hugging Face Hub.\n",
    "\n",
    "    Returns:\n",
    "        model: The optimized LLM model.\n",
    "        tokenizer: The tokenizer associated with the model.\n",
    "    \"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "    \n",
    "    # Move model to appropriate device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    # Optimize the model with torch.compile\n",
    "    optimized_model = torch.compile(model)\n",
    "    \n",
    "    return optimized_model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "def initialize_chroma(collection_name: str = \"pdf_embeddings\", db_path: str = \"./chroma_db\") -> chromadb.api.models.Collection:\n",
    "    \"\"\"\n",
    "    Initializes and returns the Chroma collection.\n",
    "\n",
    "    Args:\n",
    "        collection_name: Name of the Chroma collection.\n",
    "        db_path: Path to the Chroma DB.\n",
    "\n",
    "    Returns:\n",
    "        Chroma collection instance.\n",
    "    \"\"\"\n",
    "    chroma_client = chromadb.PersistentClient(path=db_path)\n",
    "    collection = chroma_client.get_or_create_collection(name=collection_name)\n",
    "    return collection\n",
    "\n",
    "def retrieve_documents(query: str, collection: chromadb.api.models.Collection, n_results: int = 2) -> list:\n",
    "    \"\"\"\n",
    "    Retrieves relevant documents from Chroma DB based on the query.\n",
    "\n",
    "    Args:\n",
    "        query: The user's query string.\n",
    "        collection: The Chroma collection to query.\n",
    "        n_results: Number of top results to return.\n",
    "\n",
    "    Returns:\n",
    "        List of retrieved documents.\n",
    "    \"\"\"\n",
    "    results = collection.query(\n",
    "        query_texts=[query],\n",
    "        n_results=n_results,\n",
    "        include=['documents', 'metadatas']\n",
    "    )\n",
    "    return results['documents'][0]\n",
    "\n",
    "def generate_response(model, tokenizer, prompt: str, max_length: int = 150) -> str:\n",
    "    \"\"\"\n",
    "    Generates a response using the LLM based on the prompt.\n",
    "\n",
    "    Args:\n",
    "        model: The optimized LLM model.\n",
    "        tokenizer: The tokenizer for the model.\n",
    "        prompt: The text prompt to generate the response.\n",
    "        max_length: Maximum length of the generated response.\n",
    "\n",
    "    Returns:\n",
    "        Generated text response.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(inputs, max_length=max_length, num_return_sequences=1)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_pipeline(query: str, model, tokenizer, collection: chromadb.api.models.Collection, n_results: int = 2) -> str:\n",
    "    \"\"\"\n",
    "    Performs Retrieval-Augmented Generation.\n",
    "\n",
    "    Args:\n",
    "        query: The user's query string.\n",
    "        model: The optimized LLM model.\n",
    "        tokenizer: The tokenizer for the model.\n",
    "        collection: The Chroma collection to query.\n",
    "        n_results: Number of top results to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        Generated response based on retrieved documents.\n",
    "    \"\"\"\n",
    "    # Retrieve relevant documents\n",
    "    retrieved_docs = retrieve_documents(query, collection, n_results)\n",
    "    \n",
    "    # Combine retrieved documents into context\n",
    "    context = \"\\n\\n\".join(retrieved_docs)\n",
    "    \n",
    "    # Create prompt for the LLM\n",
    "    prompt = f\"Context:\\n{context}\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "    \n",
    "    # Generate response\n",
    "    answer = generate_response(model, tokenizer, prompt)\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidDimensionException",
     "evalue": "Embedding dimension 384 does not match collection dimensionality 768",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidDimensionException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(response)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 18\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[34], line 12\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is a query about wheat\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Perform RAG\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrag_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated Response:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "Cell \u001b[0;32mIn[33], line 16\u001b[0m, in \u001b[0;36mrag_pipeline\u001b[0;34m(query, model, tokenizer, collection, n_results)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mPerforms Retrieval-Augmented Generation.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m    Generated response based on retrieved documents.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Retrieve relevant documents\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m retrieved_docs \u001b[38;5;241m=\u001b[39m \u001b[43mretrieve_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Combine retrieved documents into context\u001b[39;00m\n\u001b[1;32m     19\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(retrieved_docs)\n",
      "Cell \u001b[0;32mIn[32], line 33\u001b[0m, in \u001b[0;36mretrieve_documents\u001b[0;34m(query, collection, n_results)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mretrieve_documents\u001b[39m(query: \u001b[38;5;28mstr\u001b[39m, collection: chromadb\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mCollection, n_results: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[1;32m     22\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m    Retrieves relevant documents from Chroma DB based on the query.\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m        List of retrieved documents.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mcollection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_texts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdocuments\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmetadatas\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocuments\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/dietbot/arag/.venv/lib/python3.10/site-packages/chromadb/api/models/Collection.py:221\u001b[0m, in \u001b[0;36mCollection.query\u001b[0;34m(self, query_embeddings, query_texts, query_images, query_uris, n_results, where, where_document, include)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get the n_results nearest neighbor embeddings for provided query_embeddings or query_texts.\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    207\u001b[0m \n\u001b[1;32m    208\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    210\u001b[0m query_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_and_prepare_query_request(\n\u001b[1;32m    211\u001b[0m     query_embeddings\u001b[38;5;241m=\u001b[39mquery_embeddings,\n\u001b[1;32m    212\u001b[0m     query_texts\u001b[38;5;241m=\u001b[39mquery_texts,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    218\u001b[0m     include\u001b[38;5;241m=\u001b[39minclude,\n\u001b[1;32m    219\u001b[0m )\n\u001b[0;32m--> 221\u001b[0m query_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_request\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43membeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_request\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn_results\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_request\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwhere\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhere_document\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_request\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwhere_document\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_request\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minclude\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtenant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_query_response(\n\u001b[1;32m    233\u001b[0m     response\u001b[38;5;241m=\u001b[39mquery_results, include\u001b[38;5;241m=\u001b[39mquery_request[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minclude\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    234\u001b[0m )\n",
      "File \u001b[0;32m~/dietbot/arag/.venv/lib/python3.10/site-packages/chromadb/telemetry/opentelemetry/__init__.py:150\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/dietbot/arag/.venv/lib/python3.10/site-packages/tenacity/__init__.py:336\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    334\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    335\u001b[0m wrapped_f\u001b[38;5;241m.\u001b[39mstatistics \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mstatistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m--> 336\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dietbot/arag/.venv/lib/python3.10/site-packages/tenacity/__init__.py:475\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 475\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/dietbot/arag/.venv/lib/python3.10/site-packages/tenacity/__init__.py:376\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    374\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[0;32m--> 376\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/dietbot/arag/.venv/lib/python3.10/site-packages/tenacity/__init__.py:398\u001b[0m, in \u001b[0;36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetryCallState\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mis_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mretry_run_result):\n\u001b[0;32m--> 398\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutcome\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.15/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.15/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/dietbot/arag/.venv/lib/python3.10/site-packages/tenacity/__init__.py:478\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 478\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    480\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/dietbot/arag/.venv/lib/python3.10/site-packages/chromadb/api/segment.py:103\u001b[0m, in \u001b[0;36mrate_limit.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rate_limit_enforcer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrate_limit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dietbot/arag/.venv/lib/python3.10/site-packages/chromadb/rate_limit/simple_rate_limit/__init__.py:23\u001b[0m, in \u001b[0;36mSimpleRateLimitEnforcer.rate_limit.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dietbot/arag/.venv/lib/python3.10/site-packages/chromadb/api/segment.py:790\u001b[0m, in \u001b[0;36mSegmentAPI._query\u001b[0;34m(self, collection_id, query_embeddings, n_results, where, where_document, include, tenant, database)\u001b[0m\n\u001b[1;32m    788\u001b[0m coll \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_collection(collection_id)\n\u001b[1;32m    789\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m embedding \u001b[38;5;129;01min\u001b[39;00m query_embeddings:\n\u001b[0;32m--> 790\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_dimension\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_quota_enforcer\u001b[38;5;241m.\u001b[39menforce(\n\u001b[1;32m    793\u001b[0m     action\u001b[38;5;241m=\u001b[39mAction\u001b[38;5;241m.\u001b[39mQUERY,\n\u001b[1;32m    794\u001b[0m     tenant\u001b[38;5;241m=\u001b[39mtenant,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    798\u001b[0m     n_results\u001b[38;5;241m=\u001b[39mn_results,\n\u001b[1;32m    799\u001b[0m )\n\u001b[1;32m    801\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executor\u001b[38;5;241m.\u001b[39mknn(\n\u001b[1;32m    802\u001b[0m     KNNPlan(\n\u001b[1;32m    803\u001b[0m         Scan(coll),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    813\u001b[0m     )\n\u001b[1;32m    814\u001b[0m )\n",
      "File \u001b[0;32m~/dietbot/arag/.venv/lib/python3.10/site-packages/chromadb/api/segment.py:881\u001b[0m, in \u001b[0;36mSegmentAPI._validate_dimension\u001b[0;34m(self, collection, dim, update)\u001b[0m\n\u001b[1;32m    879\u001b[0m         collection[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdimension\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m dim\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m collection[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdimension\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m dim:\n\u001b[0;32m--> 881\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidDimensionException(\n\u001b[1;32m    882\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmbedding dimension \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match collection dimensionality \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcollection[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdimension\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m     )\n\u001b[1;32m    884\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[0;31mInvalidDimensionException\u001b[0m: Embedding dimension 384 does not match collection dimensionality 768"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Load and optimize the LLM model\n",
    "    model, tokenizer = load_optimized_llm(model_name=\"gpt2\")  # You can choose a different model\n",
    "    \n",
    "    # Initialize Chroma DB collection\n",
    "    collection = initialize_chroma(collection_name=\"pdf_embeddings\", db_path=\"./chroma_db\")\n",
    "    \n",
    "    # Example query\n",
    "    query = \"This is a query about wheat\"\n",
    "    \n",
    "    # Perform RAG\n",
    "    response = rag_pipeline(query, model, tokenizer, collection, n_results=2)\n",
    "    \n",
    "    print(\"Generated Response:\")\n",
    "    print(response)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
